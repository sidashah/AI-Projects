{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import string\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import string\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "train_path = \"aclImdb/train/\" # source data\n",
    "test_path = \"imdb_te.csv\" # test data for grade evaluation. \n",
    "\n",
    "def imdb_data_preprocess(inpath, outpath=\"./\", name=\"imdb_tr.csv\", mix=False):\n",
    "    '''Implement this module to extract\n",
    "    and combine text files under train_path directory into \n",
    "    imdb_tr.csv. Each text file in train_path should be stored \n",
    "    as a row in imdb_tr.csv. And imdb_tr.csv should have three \n",
    "    columns, \"row_number\", \"text\" and label'''\n",
    "    stopwords_filename = \"stopwords.en.txt\"\n",
    "    stopwords = []\n",
    "\n",
    "    punctuations = string.punctuation\n",
    "\n",
    "    with open(stopwords_filename,'rb+') as stopwords_file:\n",
    "        stopwords = stopwords_file.read().split('\\n')\n",
    "\n",
    "    positive_file_path = join(inpath,\"pos\")\n",
    "    negative_file_path = join(inpath,\"neg\")\n",
    "\n",
    "    row_num = 0\n",
    "\n",
    "    positive_review_files = listdir(positive_file_path)\n",
    "    for file_path in positive_review_files:\n",
    "        review_file = join(positive_file_path, file_path)\n",
    "        with open(review_file, 'rb+') as text_file:\n",
    "            review = text_file.read()\n",
    "\n",
    "            review = re.sub(r'[^\\x00-\\x7F]+',' ', review) # remove all characters other than ASCII with space\n",
    "\n",
    "            for p in punctuations:\n",
    "                review = review.replace(p, ' ')\n",
    "            reviewwords  = [word.strip().lower() for word in review.split(' ') if word.lower() not in stopwords]\n",
    "            review = ' '.join(reviewwords)\n",
    "\n",
    "            reviews.append([row_num, review, 1])\n",
    "            row_num += 1\n",
    "\n",
    "    negative_review_files = listdir(negative_file_path)\n",
    "    for file_path in negative_review_files:\n",
    "        review_file = join(negative_file_path, file_path)\n",
    "        with open(review_file, 'rb+') as text_file:\n",
    "            review = text_file.read()\n",
    "\n",
    "            review = re.sub(r'[^\\x00-\\x7F]+',' ', review) # remove all characters other than ASCII with space\n",
    "\n",
    "            for p in punctuations:\n",
    "                review = review.replace(p, ' ')\n",
    "            reviewwords  = [word.strip().lower() for word in review.split(' ') if word.lower() not in stopwords]\n",
    "            review = ' '.join(reviewwords)\n",
    "\n",
    "            reviews.append([row_num, review, 0])\n",
    "            row_num += 1\n",
    "\n",
    "    reviews_np = np.array(reviews)\n",
    "    np.savetxt(fname=name, X=reviews_np, fmt=['%s','%s','%s'], delimiter=',', header='row_number,text,polarity', comments='')\n",
    "    return name\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #train_data_file = imdb_data_preprocess(train_path)\n",
    "    train_data_file = 'imdb_tr.csv'\n",
    "    df = pd.read_csv(train_data_file)\n",
    "    text = df['text']\n",
    "    vectorizer = CountVectorizer()\n",
    "    vector_count = vectorizer.fit_transform(text)\n",
    "\n",
    "    Y = np.array(df['polarity'])\n",
    "\n",
    "    clf = SGDClassifier(loss='hinge', penalty='l1')\n",
    "    clf.fit(vector_count, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l1', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_processed_test_data():\n",
    "    df = pd.read_csv(test_path)\n",
    "    test_data = df['text'].tolist()[:5]\n",
    "    stopwords_filename = \"stopwords.en.txt\"\n",
    "    stopwords = []\n",
    "    processed_test_data = []\n",
    "\n",
    "    punctuations = string.punctuation\n",
    "\n",
    "    with open(stopwords_filename,'rb+') as stopwords_file:\n",
    "        stopwords = stopwords_file.read().split('\\n')\n",
    "\n",
    "    for review in test_data:\n",
    "\n",
    "        review = re.sub(r'[^\\x00-\\x7F]+',' ', review) # remove all characters other than ASCII with space\n",
    "        \n",
    "        for p in punctuations:\n",
    "            review = review.replace(p, ' ')\n",
    "        reviewwords  = [word.lower().strip() for word in review.split(' ') if word.lower() not in stopwords]\n",
    "        review = ' '.join(reviewwords)\n",
    "\n",
    "        processed_test_data.append(review)\n",
    "    \n",
    "    return processed_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oh gosh love movie sooooooooooooooooooooo much incredible loved wee babe still love adult favorite disney movie allllllllllllllllllllllllllllll time watch watch love friends watch ton soooooooooooooooooooooooooooooooooo good recommend anyone child child heart favorite part song dance number strays thomas malley writers producers director completely nailed one yeah nailed wall xoxo wolly xoxo',\n",
       " 'saw borderline several years ago amc looking ever since haunting visual textural sensual movie took somewhere like dream care never forget curtain blowing breeze still remember way made tilt head remember facial expression saw know happened movie find life way bother unfairness ultimate rejection innocent character strikes sadly real loved faces way camera dwelt upon camera gazed set unfocused eyes daydreamer borderline real way movies exactly lack explanation color sharpness made enter consciousness like thief night love movie someday',\n",
       " 'let say granny extremely well made horror violence sure suspense moves best indie horror movie ever seen 58 minutes long 5 20 favorite movie time people love give 10 10',\n",
       " 'like full moon pictures ordered movie usa germany get anywhere thought would nice amusing like subspecies puppetmaster series full atmosphere glad movie finally arrived watching cheesy movie disappointed actors think even say actors boring untalented story poor performance even set monster cheap lousy hope one ever make sequel remake terrible movie',\n",
       " 'worst horror film ever funniest film ever rolled one got see film cheap unbeliaveble see really p watch carrot']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = get_processed_test_data()\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_X = vectorizer.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answer = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inpath = 'aclImdb/test'\n",
    "review_X = []\n",
    "review_Y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_file_path = join(inpath,\"pos\")\n",
    "negative_file_path = join(inpath,\"neg\")\n",
    "stopwords_filename = \"stopwords.en.txt\"\n",
    "stopwords = []\n",
    "\n",
    "with open(stopwords_filename,'rb+') as stopwords_file:\n",
    "    stopwords = stopwords_file.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_review_files = listdir(positive_file_path)\n",
    "for file_path in positive_review_files:\n",
    "    review_file = join(positive_file_path, file_path)\n",
    "    with open(review_file, 'rb+') as text_file:\n",
    "        review = text_file.read()\n",
    "\n",
    "        review = re.sub(r'[^\\x00-\\x7F]+',' ', review) # remove all characters other than ASCII with space\n",
    "\n",
    "        for p in string.punctuation:\n",
    "            review = review.replace(p, ' ')\n",
    "        reviewwords  = [word.strip().lower() for word in review.split(' ') if word.lower() not in stopwords]\n",
    "        review = ' '.join(reviewwords)\n",
    "\n",
    "        review_X.append(review)\n",
    "        review_Y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "negative_review_files = listdir(negative_file_path)\n",
    "for file_path in negative_review_files:\n",
    "    review_file = join(negative_file_path, file_path)\n",
    "    with open(review_file, 'rb+') as text_file:\n",
    "        review = text_file.read()\n",
    "\n",
    "        review = re.sub(r'[^\\x00-\\x7F]+',' ', review) # remove all characters other than ASCII with space\n",
    "\n",
    "        for p in string.punctuation:\n",
    "            review = review.replace(p, ' ')\n",
    "        reviewwords  = [word.strip().lower() for word in review.split(' ') if word.lower() not in stopwords]\n",
    "        review = ' '.join(reviewwords)\n",
    "\n",
    "        review_X.append(review)\n",
    "        review_Y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vector_X = vectorizer.transform(review_X)\n",
    "Y = np.array(review_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
